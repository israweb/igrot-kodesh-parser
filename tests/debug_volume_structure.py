#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ĞÑ‚Ğ»Ğ°Ğ´Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ñ‚Ğ¾Ğ¼Ğ¾Ğ²
"""

import sys
import os
sys.path.append('../main')

from letters_downloader import LettersDownloader
import re


def debug_volume_structure():
    """Ğ˜Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‚Ğ¾Ğ¼Ğ°"""
    
    # Ğ’Ğ¾Ğ·ÑŒĞ¼ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ñ‚Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    volume_url = "https://www.chabad.org/therebbe/article_cdo/aid/4643805/jewish/page.htm"
    
    print("ğŸ” ×—×§×¨ ××‘× ×” ×“×£ ×›×¨×š")
    print("=" * 50)
    print(f"ğŸ“– × ×™×ª×•×— ×›×¨×š: {volume_url}")
    
    try:
        downloader = LettersDownloader(download_dir="temp", headless=False)  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ
        soup = downloader.get_page_with_selenium(volume_url)
        if not soup:
            print("âŒ ×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×”×“×£")
            return
        
        print(f"âœ… ×”×“×£ ×˜×¢×•×Ÿ ×‘×”×¦×œ×—×”")
        print(f"ğŸ“„ ×’×•×“×œ HTML: {len(str(soup))} ×ª×•×•×™×")
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ ÑÑÑ‹Ğ»ĞºĞ¸
        print("\nğŸ”— × ×™×ª×•×— ×›×œ ×”×§×™×©×•×¨×™×:")
        print("-" * 50)
        
        all_links = soup.find_all('a', href=True)
        print(f"×¡×š ×”×›×œ × ××¦××• ×§×™×©×•×¨×™×: {len(all_links)}")
        
        # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼
        letter_candidates = []
        navigation_links = []
        other_links = []
        
        for link in all_links:
            href = link['href']
            text = link.get_text(strip=True)
            
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ Ğ¸Ğ»Ğ¸ Ğ¾Ñ‡ĞµĞ½ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ñ‹
            if not text or len(text) < 2:
                continue
                
            # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸
            if 'article_cdo' in href and any(char.isdigit() for char in text):
                if 'page.htm' not in href:  # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‚Ğ¾Ğ¼Ğ¾Ğ²
                    letter_candidates.append((text, href))
            elif any(nav in text.lower() for nav in ['browse', 'next', 'previous', 'home', 'back']):
                navigation_links.append((text, href))
            else:
                other_links.append((text, href))
        
        print(f"\nğŸ“ ×›×ª×‘×™× ×¤×•×˜× ×¦×™××œ×™×™× ({len(letter_candidates)}):")
        for i, (text, href) in enumerate(letter_candidates[:10], 1):  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10
            print(f"   {i}. {text}")
            print(f"      URL: {href}")
        
        if len(letter_candidates) > 10:
            print(f"   ... ×•×¢×•×“ {len(letter_candidates) - 10} ×—×•×§×¨×™×")
        
        print(f"\nğŸ§­ ×§×™×©×•×¨×™× × ×™×•×•×˜ ({len(navigation_links)}):")
        for text, href in navigation_links[:5]:
            print(f"   - {text} -> {href}")
        
        print(f"\nğŸ”— ×§×™×©×•×¨×™× ××—×¨×™× ({len(other_links)}):")
        for text, href in other_links[:5]:
            print(f"   - {text} -> {href}")
        
        # ĞŸĞ¾Ğ¸ÑĞº ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²
        print(f"\nğŸ” ×—×™×¤×•×© ×¤×˜×¨× ×™× ×¡×¤×¦×™×¤×™×™×:")
        print("-" * 50)
        
        # Ğ˜Ñ‰ĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸ Ñ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸
        date_pattern = r'\d{1,2}[./]\d{1,2}[./]\d{2,4}'
        date_links = []
        for link in all_links:
            text = link.get_text(strip=True)
            if re.search(date_pattern, text):
                date_links.append((text, link['href']))
        
        print(f"ğŸ“… ×§×™×©×•×¨×™× ×¢× ×ª××¨×™×›×™× ({len(date_links)}):")
        for text, href in date_links[:10]:
            print(f"   - {text} -> {href}")
        
        # Ğ˜Ñ‰ĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸ Ñ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ¿Ğ¸ÑĞµĞ¼
        number_pattern = r'(?:letter|Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾|××›×ª×‘).*?\d+|^\d+\.'
        numbered_links = []
        for link in all_links:
            text = link.get_text(strip=True)
            if re.search(number_pattern, text, re.IGNORECASE):
                numbered_links.append((text, link['href']))
        
        print(f"\nğŸ”¢ ×§×™×©×•×¨×™× ×¢× ××¡×¤×¨×™× ({len(numbered_links)}):")
        for text, href in numbered_links[:10]:
            print(f"   - {text} -> {href}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ²
        print(f"\nğŸ“‹ × ×™×ª×•×— ××‘× ×” ×“×£:")
        print("-" * 50)
        
        # Ğ˜Ñ‰ĞµĞ¼ ÑĞ¿Ğ¸ÑĞºĞ¸ (ul, ol)
        lists = soup.find_all(['ul', 'ol'])
        print(f"× ××¦××• ×¨×©×™××•×ª: {len(lists)}")
        
        for i, lst in enumerate(lists[:3], 1):
            items = lst.find_all('li')
            print(f" ×¨×©×™××” {i}: {len(items)} ×¤×¨×™×˜×™×")
            if items:
                for j, item in enumerate(items[:3], 1):
                    link = item.find('a')
                    if link:
                        print(f"    {j}. {link.get_text(strip=True)[:50]}...")
        
        # Ğ˜Ñ‰ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹
        tables = soup.find_all('table')
        print(f"\n× ××¦××• ×˜×‘×œ××•×ª: {len(tables)}")
        
        for i, table in enumerate(tables[:2], 1):
            rows = table.find_all('tr')
            print(f"  ×˜×‘×œ×” {i}: {len(rows)} ×©×•×¨×•×ª")
            if rows:
                for j, row in enumerate(rows[:3], 1):
                    cells = row.find_all(['td', 'th'])
                    if cells and len(cells) > 0:
                        text = cells[0].get_text(strip=True)[:30]
                        print(f"    {j}. {text}...")
        
        # Ğ˜Ñ‰ĞµĞ¼ div-Ñ‹ Ñ ĞºĞ»Ğ°ÑÑĞ°Ğ¼Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ğ¿Ğ¸ÑÑŒĞ¼Ğ°
        print(f"\nğŸ“¦ × ×™×ª×•×— ×©×™× ×•×™×™× DIV:")
        divs_with_class = soup.find_all('div', class_=True)
        class_counts = {}
        for div in divs_with_class:
            classes = ' '.join(div.get('class', []))
            class_counts[classes] = class_counts.get(classes, 0) + 1
        
        print("×›×™× ×•×™×™× ×¨××©×•× ×™× ×©×œ ×©×™× ×•×™×™× DIV:")
        for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  .{cls}: {count} ×©×™× ×•×™×™×")
        
        input("\nâ¸ï¸  ×œ×—×¥ ×¢×œ Enter ×›×“×™ ×œ×¡×’×•×¨ ××ª ×”×“×¤×“×¤×Ÿ ×•×œ×”×©×œ×™× ××ª ×”×—×§×™×¨×”...")
        
        downloader.close()
        
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")


if __name__ == "__main__":
    debug_volume_structure()
