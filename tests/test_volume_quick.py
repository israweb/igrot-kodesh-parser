#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾Ğ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ°
"""

import sys
import os
sys.path.append('../main')

from letters_downloader import LettersDownloader
import argparse


def quick_test_volume(volume_name="×", expected_count=None, max_pages_to_test=3):
    """
    Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ñ‚Ğ¾Ğ¼Ğ° Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼
    
    Args:
        volume_name (str): ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¼Ğ° (×, ×‘, ×’ Ğ¸ Ñ‚.Ğ´.)
        expected_count (int): ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¸ÑĞµĞ¼
        max_pages_to_test (int): ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    """
    print(f"âš¡ ×‘×“×™×§×” ××”×™×¨×” ×©×œ ×¤×¨×¡×¨ ××›×ª×‘×™× {volume_name}")
    print("=" * 50)
    
    start_url = "https://www.chabad.org/therebbe/article_cdo/aid/4643797/jewish/page.htm"
    
    try:
        downloader = LettersDownloader(download_dir="test_quick", headless=True)
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ³Ğ»Ğ°Ğ²Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ
        print("ğŸ” ×˜×¢×™× ×ª ×“×£ ×¨××©×™...")
        soup = downloader.get_page_with_selenium(start_url)
        if not soup:
            print("âŒ ×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×”×“×£ ×”×¨××©×™")
            return False
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ğ¼Ğ°
        volume_links = downloader.find_volume_links(soup, start_url)
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ¼
        target_volume = None
        for volume_info in volume_links:
            if f'×›×¨×š {volume_name}' in volume_info['title']:
                target_volume = volume_info
                break
        
        if not target_volume:
            print(f"âŒ ×¡×¤×¨ '×›×¨×š {volume_name}' ×œ× × ××¦×")
            available = [v['title'] for v in volume_links]
            print(f"×¡×¤×¨×™× ×–××™× ×™×: {', '.join(available)}")
            return False
        
        print(f"âœ… ×¡×¤×¨ × ××¦×: {target_volume['title']}")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ Ñ‚Ğ¾Ğ¼Ğ°
        print("ğŸ“„ ×˜×¢×™× ×ª ×“×£ ×¡×¤×¨...")
        volume_soup = downloader.get_page_with_selenium(target_volume['url'])
        if not volume_soup:
            print("âŒ ×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×“×£ ×”×¡×¤×¨")
            return False
        
        # Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¸ÑĞµĞ¼ (Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ñ‚Ñ‹)
        print(f"ğŸ“ ×‘×“×™×§×ª ×—×™×¤×•×© ××›×ª×‘×™× (××§×¡×™××•× {max_pages_to_test} ×“×¤×™×)...")
        
        # ĞœĞ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
        original_max_pages = 50
        
        # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¿Ğ°Ñ‚Ñ‡Ğ¸Ğ¼ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ² Ğ¿Ğ°Ñ€ÑĞµÑ€Ğµ
        letters = []
        current_page = 1
        
        while current_page <= max_pages_to_test:
            if current_page == 1:
                page_url = target_volume['url']
                page_soup = volume_soup
            else:
                page_url = f"{target_volume['url']}/page/{current_page}"
                print(f"  ğŸ“„ ×˜×¢×™× ×ª ×“×£ {current_page}: {page_url}")
                page_soup = downloader.get_page_with_selenium(page_url)
                if not page_soup:
                    print(f"  âŒ ×“×£ {current_page} ×œ× × ××¦×")
                    break
            
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¿Ğ¸ÑÑŒĞ¼Ğ° ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
            page_letters = downloader._extract_letters_from_page(
                page_soup, page_url, target_volume['title'], current_page
            )
            
            if page_letters:
                letters.extend(page_letters)
                print(f"  ğŸ“ ×“×£ {current_page}: × ××¦××• {len(page_letters)} ××›×ª×‘×™×")
            else:
                print(f"  ğŸ“ ×“×£ {current_page}: ××›×ª×‘×™× ×œ× × ××¦××•")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
            next_page_link = page_soup.find('a', {'id': 'Paginator_NextPage'})
            if not next_page_link:
                next_link = page_soup.find('link', {'rel': 'next'})
                if not next_link:
                    print(f"  ğŸ“„ ×”×’×¢× ×• ×œ×“×£ ×”××—×¨×•×Ÿ: {current_page}")
                    break
            
            current_page += 1
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
        unique_letters = []
        seen_urls = set()
        for letter in letters:
            if letter['url'] not in seen_urls:
                seen_urls.add(letter['url'])
                unique_letters.append(letter)
        
        # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        print(f"\nğŸ“Š ×ª×•×¦××•×ª ×‘×“×™×§×” ××”×™×¨×”:")
        print("-" * 50)
        print(f"ğŸ“„ ×“×¤×™× ×©× ×‘×“×§×•: {min(current_page, max_pages_to_test)}")
        print(f"ğŸ“ ××›×ª×‘×™× × ××¦××•: {len(unique_letters)}")
        print(f"ğŸ”— URL ×™×™×—×•×“×™×™×: {len(seen_urls)}")
        
        if expected_count:
            estimated_total = len(unique_letters) * (expected_count / (50 * max_pages_to_test))
            print(f"ğŸ¯ ×›××•×ª ×›×•×œ×œ×ª ×¦×¤×•×™×”: {expected_count}")
            print(f"ğŸ“ˆ ×”×¢×¨×›×” ×œ×¤×™ ×“×¤×™× ×©× ×‘×“×§×•: ~{estimated_total:.0f}")
            
            if abs(estimated_total - expected_count) < expected_count * 0.2:  # 20% Ğ´Ğ¾Ğ¿ÑƒÑĞº
                print("âœ… ×”×¢×¨×›×” ×§×¨×•×‘×” ×œ×¦×¤×•×™×” - ×”×¤×¨×¡×¨ ×¢×•×‘×“ ×›×¨××•×™")
                success = True
            else:
                print("âš ï¸  ×”×¢×¨×›×” ×¨×—×•×§×” ××”×¦×¤×•×™×” - ×™×™×ª×›×Ÿ ×‘×¢×™×•×ª")
                success = False
        else:
            success = len(unique_letters) > 0
        
        # ×“×•×’×××•×ª ×œ××›×ª×‘×™× ×©× ××¦××•
        if unique_letters:
            print(f"\nğŸ“‹ ×“×•×’×××•×ª ×œ××›×ª×‘×™× ×©× ××¦××•:")
            for i, letter in enumerate(unique_letters[:5], 1):
                print(f"   {i}. {letter['title']}")
        
        # ×‘×“×™×§×ª ××‘× ×”
        pages_found = set(letter.get('page', 1) for letter in unique_letters)
        print(f"\nğŸ“„ ××›×ª×‘×™× × ××¦××• ×‘×“×¤×™×: {sorted(pages_found)}")
        
        downloader.close()
        return success
        
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='×‘×“×™×§×” ××”×™×¨×” ×©×œ ×¤×¨×¡×¨ ××›×ª×‘×™×')
    parser.add_argument('--volume', default='×', help='×¡×¤×¨ ×œ×‘×“×™×§×” (×, ×‘, ×’...)')
    parser.add_argument('--expected', type=int, help='×›××•×ª ××›×ª×‘×™× ×¦×¤×•×™×”')
    parser.add_argument('--pages', type=int, default=3, help='××§×¡×™××•× ×“×¤×™× ×œ×‘×“×™×§×”')
    
    args = parser.parse_args()
    
    print("âš¡ ×‘×“×™×§×” ××”×™×¨×” ×©×œ ×¤×¨×¡×¨ ××›×ª×‘×™×")
    print("=" * 50)
    print(f"ğŸ“– ×¡×¤×¨: ×›×¨×š {args.volume}")
    expected_count = args.expected or (169 if args.volume == '×' else None)
    if expected_count:
        print(f"ğŸ¯ ××›×ª×‘×™× ×¦×¤×•×™×™×: {expected_count}")
    print(f"ğŸ“„ ××§×¡×™××•× ×“×¤×™×: {args.pages}")
    print("=" * 50)
    
    success = quick_test_volume(args.volume, expected_count, args.pages)
    
    if success:
        print("\nâœ… ×‘×“×™×§×” ××”×™×¨×” ×‘×•×¦×¢×”!")
        print("ğŸ’¡ ×œ×‘×“×™×§×” ××œ××” ×™×•×¤×¢×œ: python test_volume_completeness.py")
    else:
        print("\nâŒ ×‘×“×™×§×” ××”×™×¨×” ×’×™×œ×” ×‘×¢×™×•×ª!")
        print("ğŸ”§ ××•××œ×¥ ×œ×”×¤×¢×™×œ ×‘×“×™×§×” ××œ××” ×œ× ×™×ª×•×— ××¤×•×¨×˜")


if __name__ == "__main__":
    main()
